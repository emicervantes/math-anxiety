---
title: "Modeling Final Report"
editor: visual
author: Emi Cervantes
toc: true
date: "7-28-2023"
number-sections: true
highlight-style: pygments
format: 
  html: 
    code-fold: false
    html-math-method: katex
    fig-width: 7
    fig-height: 4
  pdf:
    toc: true
    number-sections: true
    geometry:
      - top=30mm
      - left=20mm
    fig-width: 7
    fig-height: 4
  docx: 
    fig-width: 10
    fig-height: 5
---

# Load Libraries

```{r}
library(tidyverse)
library(lavaan)
library(semPlot)
library(semptools)
```

# Load Dataset

```{r}
df <- readxl::read_xlsx('../../../data/math-anxiety-raw-data.xlsx')
```

## Clean Dataset

```{r}
tma_lst <- c("TMA_1", "TMA_2", "TMA_3","TMA_4", "TMA_5", "TMA_6",
             "TMA_sum", "TMA_avg")
df1 <- df %>% select(Condition, Sex, chicago, nonwhite, pretest,
              MW_day1_avg, MW_day2_avg, SI_avg, tma_lst,
              Understand_avg, Del_OverallAcc)
# Get rid of row that has NA values in Condition and/or Sex
df1 <- df1 %>% filter(Condition == 1 | Condition == 2)
df1 <- df1 %>% filter(!is.na(Sex))
df1$Condition[df1$Condition == 2] <- 0
# Assign 0 for "boy" and 1 for "girl"
df1$Sex[df1$Sex == 1] <- 0
df1$Sex[df1$Sex == 2] <- 1
# Make sure variable is categorical
df1$chicago <- as.factor(df1$chicago)
df1$Sex <- as.factor(df1$Sex)
df1$nonwhite <- as.factor(df1$nonwhite)
df1$Condition <- as.factor(df1$Condition)
```

# Checking Pretest Score Difference

```{r}
df1 %>% group_by(chicago) %>% summarize(pre_avg = mean(pretest, na.rm = TRUE)) %>% ggplot(aes(x = chicago, y = pre_avg))+ 
  geom_bar(position = "dodge", stat = "identity", color = "black",
           fill = "#ef476f", alpha = 0.5) + 
  geom_text(aes(label=round(pre_avg,2)),  position=position_dodge(width=0.9), 
            vjust=-0.25) +
  ylim(0,1) +
  labs(x = "Location", y = "Pretest Score") + 
  scale_x_discrete(labels=c("Irvine", "Chicago")) +
  theme_light()
```


In the previous analysis, we saw that more student in Irvine already knew how to use ratio tactics before the study than students in Chicago. We want to check if the pretest score difference is significant across the sites by using student's t-test:

```{r}
t.test(pretest ~ chicago, data = df1)
```

The result shows that the difference is significant (p-value = 0.03). Since both sites are significantly different, we will treat each site as separate data. 

## Split data into Chicago and Irvine

```{r}
# chicago data
df_i <- df1 %>% filter(chicago == 1)
# irvine data
df_c <- df1 %>% filter(chicago == 0)
```

# Checking Gender Difference in Math Anxiety

```{r}
# labels 
cond <- c("No Worked EX", "Worked EX")
names(cond) <- c(0, 1)
location <- c("Irvine", "Chicago")
names(location) <- c(0, 1)
# TMA mean by site, condition, and gender
mu <- df1 %>% group_by(chicago, Condition, Sex) %>% summarize(mean = mean(TMA_avg))
# math anxiety density plot
df1 %>% ggplot(aes(x = TMA_avg, fill = Sex,
                   color = Sex)) +
  geom_density(alpha = 0.2) +
  theme_light() +
  geom_vline(data=mu, aes(xintercept=mean, color=Sex),
           linetype="dashed") +
  facet_grid(rows = vars(Condition),
             cols = vars(chicago),
             labeller = labeller(Condition = cond,
                                 chicago = location)) +
  scale_fill_manual(values = c("#FFC20A", "#0C7BDC"), labels = c("Boy", "Girl")) +
  scale_color_manual(values = c("#FFC20A", "#0C7BDC"), labels = c("Boy", "Girl")) +
  labs(x = "Math Anxiety", y = "Density",
       fill = "Gender", color = "Gender") +theme(legend.position="bottom")
```

We see from the figure that in Irvine schools, girls seemed to have a higher average math anxiety than boys in both condition. However, in Chicago schools, boys seemed to have a higher math anxiety than girls in both condition.

Girls seemed to have a higher math anxiety compared to boys overall. Check if the difference is significant in each site by using ANOVA test:

## Chicago Data

```{r}
m1_c <- aov(TMA_avg ~ Condition + Sex + Condition*Sex, 
          data = df_c)
summary(m1_c)
```

No significant difference between gender on learning achievement and math anxiety was found by gender.

## Irvine Data

```{r}
m1_i <- aov(TMA_avg ~ Condition + Sex + Condition*Sex, 
          data = df_i)
summary(m1_i)
```

No significant difference between gender on learning achievement and math anxiety was found by gender.

# Multiple Linear Regression

We will be fitting a model to our data: one for predicting `Del_OverallAcc` and `Understand_avg`. The model uses following predictors:

-   `Condition`
-   `Sex`
-   `pretest`
-   `TMA_avg`
-   `MW_day1_avg` and `MW_day2_avg`
-   `SI_avg`
-   Interaction Terms: `Condition*Sex`, `Condition*TMA_avg`, `Condition*TMA_avg*Sex`

To answer our research question we are interested in answering these hypotheses:

$H_0$: $\beta_{Condition*Sex} = 0$

$H_1$: $\beta_{Condition*Sex} \neq 0$, interaction term between `Condition` and `Sex` is significant

## Posttest Accuracy Scores

```{r}
# Check if there's any participant missing accuracy score data
df1 %>% count(is.na(Del_OverallAcc))
```

Every participant has a `Del_OverallAcc` data, now we fit the model to our data to predict `Del_OverallAcc`:

### Chicago Data

```{r}
# Fit model
m2_c <- Del_OverallAcc ~ Condition + Sex + pretest + TMA_avg + MW_day1_avg + MW_day2_avg + SI_avg + Condition*Sex + Condition*TMA_avg + Condition*TMA_avg*Sex
fit2_c <- lm(m2_c, data = df_c)
summary(fit2_c)
```

*Significant Predictors:*

-   `pretest` (p = 3.79e-07)
-   `SI_avg` (p = 0.0154): While controlling for other predictors, every one unit increse in `SI_avg` results in 0.04 increase in `Del_OverallAcc`
-  `TMA_avg:Condition` (p = 0.0133): Students who received worked examples, while controlling for other predictors, had increase in `Del_OverallAcc` by 0.07 for every 1 unit increase in `TMA_avg`, while students who received worked examples had decrease in `Del_OverallAcc`.

### Irvine Data

```{r}
# Fit model
m2_i <- Del_OverallAcc ~ Condition + Sex + pretest + TMA_avg + MW_day1_avg + MW_day2_avg + SI_avg + Condition*Sex + Condition*TMA_avg + Condition*TMA_avg*Sex
fit2_i <- lm(m2_i, data = df_i)
summary(fit2_i)
```

*Significant Predictors*

No significant factor was found

In both sites, we failed to reject the null. That is, we did not find enough evidence to prove that gender played significant effect on math anxiety and learning achievements.

## Perceived Understanding

```{r}
# Check if there's any participant missing understanding data
df1 %>% count(is.na(Understand_avg))
```

2 participants were missing Understand_avg data (row #56 and #198)

```{r}
# Fill out missing understanding avg data with the group average
understand_avg1 <- df1 %>% filter(Condition == 1 & Sex == 0 & chicago == 0) %>% summarize(mean_understand = mean(Understand_avg, na.rm = TRUE))
understand_avg2 <- df1 %>% filter(Condition == 0 & Sex == 0 & chicago == 0) %>% summarize(mean_understand = mean(Understand_avg, na.rm = TRUE))
# assign imputed value
df1[56, 17] = understand_avg1
df1[198, 17] = understand_avg1
# update chicago and irvine data
df_c <- df1 %>% filter(chicago == 1)
df_i <- df1 %>% filter(chicago == 0)
```

Every participant now has a `Understand_avg` data, now we fit the model to our data to predict `Understand_avg`:

### Chicago Data

```{r}
# Fit model
m3_c <- Understand_avg ~ Condition + Sex + pretest + TMA_avg + MW_day1_avg + MW_day2_avg + SI_avg + Condition*Sex + Condition*TMA_avg + Condition*TMA_avg*Sex
fit3_c <- lm(m3_c, data = df_c)
summary(fit3_c)
```

No significant predictor was found in predicting `Understand_avg`.

### Irvine Data

```{r}
# Fit model
m3_i <- Understand_avg ~ Condition + Sex + pretest + TMA_avg + MW_day1_avg + MW_day2_avg + SI_avg + Condition*Sex + Condition*TMA_avg + Condition*TMA_avg*Sex
fit3_i <- lm(m3_i, data = df_i)
summary(fit3_i)
```

*Significant Predictors*

`pretest` (p = 0.0044)

`MW_day1_avg` (p = .0220): While controlling for other predictors, every 1 unit of increase in `MW_day1_avg` decreases perceived understanding by 5.1670.

`SI_avg` (p = 3.55e-05): While controlling for other predictors, every 1 unit of increase in `SI_avg` increases perceived understanding by 7.2430.

```{r}
# Display result as a table
```

## Results

No significant effect was found by gender on either math anxiety or learning achievements

However, we saw that worked examples were overall effective in reducing the effect of math anxiety on posttest accuracy scores, regardless of gender but only in Chicago.

No significant effect was found by math anxiety on perceived understanding. Instead, mind wandering and situational interest were two dominant significant predictors, but only in Irvine.

Students in Chicago significantly performed worst in learning achievements

# Path Analysis

We constructed structural equation models to model learning achievements: `Del_OverallAcc` and `Understand_avg`. We fit the model for each site data (`df_c` and `df_i`), and chi-square test was used to determine if the free model was significantly different from the constrined model.

## Posttest Acucracy Scores

```{r}
# model definition
m_acc <- '
  TMA_avg ~ 1 + MW_day1_avg + MW_day2_avg + SI_avg + Condition
  Del_OverallAcc ~ 1 + TMA_avg + Condition
'
```

### Chicago Data

```{r}
# free model
fit_ca <- sem(m_acc, data = df_c, group = "Sex")
# constrained model
fit_ca_c <- sem(m_acc, data = df_c, group = "Sex",
                group.equal = c("intercepts", "regressions"))
```

```{r}
# check if the constrained and free models are significantly diff
anova(fit_ca, fit_ca_c)
```

No significant difference between the free and constrained models for Chicago in modeling `Del_OverallAcc`.

### Irvine Data

```{r}
# free model
fit_ia <- sem(m_acc, data = df_i, group = "Sex")
# constrained model
fit_ia_c <- sem(m_acc, data = df_i, group = "Sex",
                group.equal = c("intercepts", "regressions"))
```

```{r}
summary(fit_ia)
```


```{r}
# check if the constrained and free models are significantly diff
anova(fit_ia, fit_ia_c)
```

Chi-squared difference test showed a significant result (p = 0.004444), which indicated that free model and constrained models are significantly different. Now, we need to see which predictors are different.

```{r}
m_a2 <- '
  TMA_avg ~ 1 + MW_day1_avg + MW_day2_avg + SI_avg + Condition
  Del_OverallAcc ~ 1 + c("b1", "b1") * TMA_avg + Condition
'
```

```{r}
fit_ia2 <- sem(m_a2, df_i, group = "Sex")
anova(fit_ia2, fit_ia)
```

We find that the models are still significantly different, implying that the path between `TMA_avg` -> `Del_OverallAcc` should not be constrained and instead that it should be left to vary among gender.

### Visualize Results

```{r}
# Chicago
semPaths(fit_ca,
         whatLabels = "est",
         sizeMan = 10,
         edge.label.cex = 1.15,
         style = "ram",
         nCharNodes = 0, nCharEdges = 0,
         nodeLabels = c("Math\nAnxiety", "Accuracy",
                        "MW 1","MW 2", "SI", "Condition"),
         intercepts = FALSE)

# Irvine
semPaths(fit_ia,
         whatLabels = "est",
         sizeMan = 10,
         edge.label.cex = 1.15,
         style = "ram",
         nCharNodes = 0, nCharEdges = 0,
         nodeLabels = c("Math\nAnxiety", "Accuracy",
                        "MW 1","MW 2", "SI", "Condition"),
         intercepts = FALSE)
```


## Perceived Understanding

```{r}
# model definition
m_und <- '
  TMA_avg ~ 1 + MW_day1_avg + MW_day2_avg + SI_avg + Condition
  Understand_avg ~ 1 + TMA_avg + Condition
'
```

### Chicago Data

```{r}
# free model
fit_cu <- sem(m_und, data = df_c, group = "Sex")
# constrained model
fit_cu_c <- sem(m_und, data = df_c, group = "Sex",
                group.equal = c("intercepts", "regressions"))
```

```{r}
# check if the constrained and free models are significantly diff
anova(fit_cu, fit_cu_c)
```

No significant difference between the free and constrained models for Chicago in modeling `Understand_avg`.

### Irvine Data

```{r}
# free model
fit_iu <- sem(m_und, data = df_i, group = "Sex")
# constrained model
fit_iu_c <- sem(m_und, data = df_i, group = "Sex",
                group.equal = c("intercepts", "regressions"))
```

```{r}
# check if the constrained and free models are significantly diff
anova(fit_iu, fit_iu_c)
```

Chi-squared difference test showed a significant result (p = 0.004444), which indicated that free model and constrained models are significantly different. Now, we need to see which predictors are different.

```{r}
m_u2 <- '
  TMA_avg ~ 1 + MW_day1_avg + MW_day2_avg + SI_avg + Condition
  Understand_avg ~ 1 + c("b1", "b1") * TMA_avg + Condition
'
```

```{r}
fit_iu2 <- sem(m_u2, df_i, group = "Sex")
anova(fit_iu2, fit_iu)
```

In this case, there is not a significant difference between the two models (P = 0.659), implying that there is no difference in the fit of the constrained model and the unconstrained model and that this constraint is valid.

### Visualize Results

```{r}
# Chicago
semPaths(fit_cu,
         whatLabels = "est",
         sizeMan = 10,
         edge.label.cex = 1.15,
         style = "ram",
         nCharNodes = 0, nCharEdges = 0,
         nodeLabels = c("Math\nAnxiety", "Accuracy",
                        "MW 1","MW 2", "SI", "Condition"),
         intercepts = FALSE)

# Irvine
semPaths(fit_iu,
         whatLabels = "est",
         sizeMan = 10,
         edge.label.cex = 1.15,
         style = "ram",
         nCharNodes = 0, nCharEdges = 0,
         nodeLabels = c("Math\nAnxiety", "Accuracy",
                        "MW 1","MW 2", "SI", "Condition"),
         intercepts = FALSE)
```






